# Developing Laplacians.jl

[TOC]

Just go for it.
Don't worry about writing fast code at first.
Just get it to work.
We can speed it up later.
The yinsGraph.ipynb notebook contains some examples of speed tests.
Within some of the files, I am keeping old, unoptimized versions of code around for comparison (and for satisfaction).  I will give them the name "XSlow"

## Using sparse matrices as graphs
The routines `deg`, `nbri` and `weighti` will let you treat a sparse matrix like a graph.

`deg(graph, u)` is the degree of node u.
`nbri(graph, u, i)` is the ith neighbor of node u.
`weighti(graph, u, i)` is the weight of the edge to the ith neighbor of node u.

Note that we start indexing from 1.

For example, to iterate over the neighbors of node v,
  and play with the attached nodes, you could write code like:

~~~julia
  for i in 1:deg(mat, v)
     nbr = nbri(mat, v, i)
     wt = weighti(mat, v, i)
     foo(v, nbr, wt)
  end
~~~

But, this turns out to be much slower than working with the structure directly, like

~~~julia
  for ind in mat.colptr[v]:(mat.colptr[v+1]-1)
      nbr = mat.rowval[ind]
      wt = mat.nzval[ind]
      foo(v, nbr, wt)
  end
~~~

* [ ] Maybe we can make a macro to replace those functions.  It could be faster and more readable.

### The SparseMatrixCSC data structure

You can explore what is going on with the data structure by looking at some examples.  For example, here is a randomly weighted complete graph on 4 vertices, first displayed as a matrix:

~~~julia
gr = round(10*uniformWeight(completeGraph(4)))

4x4 sparse matrix with 12 Float64 entries:
	[2, 1]  =  3.0
	[3, 1]  =  3.0
	[4, 1]  =  6.0
	[1, 2]  =  3.0
	[3, 2]  =  1.0
	[4, 2]  =  2.0
	[1, 3]  =  3.0
	[2, 3]  =  1.0
	[4, 3]  =  7.0
	[1, 4]  =  6.0
	[2, 4]  =  2.0
	[3, 4]  =  7.0
	
full(gr)

4x4 Array{Float64,2}:
 0.0  3.0  3.0  6.0
 3.0  0.0  1.0  2.0
 3.0  1.0  0.0  7.0
 6.0  2.0  7.0  0.0
~~~

To see the underlying data structure, use `fieldnames`.

~~~julia
fieldnames(gr)

5-element Array{Symbol,1}:
 :m     
 :n     
 :colptr
 :rowval
 :nzval 
~~~

`m` and `n` are the dimensions of the matrix.
The entries of the matrix are stored in nzval.
colptr[i] is the index in nzval of the first nonzero entry
in column i.  rowval tells you which rows in each column are nonzero.
The indices of the nonzero entries in column i are stored in 
rowval[colptr[i]] through rowval[colptr[i+1]-1].

~~~julia
gr.colptr 

5-element Array{Int64,1}:
  1
  4
  7
 10
 13
 
 [gr.rowval gr.nzval]
 
 12x2 Array{Float64,2}:
 2.0  3.0
 3.0  3.0
 4.0  6.0
 1.0  3.0
 3.0  1.0
 4.0  2.0
 1.0  3.0
 2.0  1.0
 4.0  7.0
 1.0  6.0
 2.0  2.0
 3.0  7.0
~~~


## Documentation

This documentation is still very rough.
It is generated by a combination of Markdown and semi-automatic generation.  The steps to generate and improve it are:

* Edit Markdown files in the `docs` directory.  For example, you could use MacDown to do this.
* If you want to add a new page to the documention, create one.  Edit the file mkdocs.yml so show where it should appear.
* Add docstrings to everything that needs it, and in particular to the routines you create.  The API is built from the docstrings.  To build the API, type

~~~julia
include("docs/build.jl")
~~~

* Run `mkdocs build` in the root directory to regenerate the documentation from the Markdown.

* Once you like the documentation, you can upload it with 

~~~
mkdocs gh-deploy -b gh-pages
~~~

* If you create a Julia notebook that you would like to include as documentation.   You should
   * put it in the notebooks directory (.julia/v0.4/Laplacians/notebooks) 
   * convert it to html and then put the html in the docs directory.

~~~
ipython nbconvert MyNotebook.ipynb
mv MyNotebook.html ../docs
~~~

   

   * move the html into the gh-pages branch.  You do this by switching to the gh-pages branch, grabbing the file from the master branch (if that's where it was), and the committing.  Like this

~~~
git checkout gh-pages
git checkout master -- docs/FirstNotebook.html
git commit
git push origin gh-pages
git checkout master      
~~~
   
### Parametric Types

A sparse matrix has two types associated with it: the types of its indices (some sort of integer) and the types of its values (some sort of number).  Most of the code has been written so that once these types are fixed, the type of everything else in the function has been too.  This is accomplished by putting curly braces after a function name, with the names of the types that we want to use in the braces.  For example,

~~~julia
shortestPaths{Tv,Ti}(mat::SparseMatrixCSC{Tv,Ti}, start::Ti)
~~~

`Tv`, sometimes written `Tval` denotes the types of the values, and `Ti` or `Tind` denotes the types of the indices.  This function will only be called if the node from which we compute the shortest paths, `start` is of type `Ti`.  Inside the code, whenever we write something like `pArray = zeros(Ti,n)`, it creates an array of zeros of type Ti.  Using these parameteric types is *much* faster than leaving the types unfixed.

### Data structures:

* `IntHeap` a heap that stores small integers (like indices of nodes in a graph) and that makes deletion fast.  Was much faster than using Julia's more general heap.

### Interface issue:
There are many different sorts of things that our code could be passing around.  For example, kruskal returns a graph as a sparse matrix.  But, we could use a format that is more specialized for trees, like the RootedTree type.  At some point, when we optimize code, we will need to figure out the right interfaces between routines.  For example, some routines symmetrize at the end.  This is slow, and should be skipped if not necessary.  It also doubles storage.

### Writing tests:
I haven't written any yet.  I'll admit that I'm using the notebooks as tests.  If I can run all the cells, then it's all good.

## Integration with other packages.

There are other graph packages that we might want to sometimes use.

* [Graphs.jl](http://github.com/JuliaLang/Graphs.jl) : I found this one to be too slow and awkward to be useful.
* [LightGraphs.jl](http://github.com/JuliaGraphs/LightGraphs.jl) : this looks more promising.  We will have to check it out.
